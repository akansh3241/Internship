{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEB SCRAPING ASSIGNMENT - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore”in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\akans\\Downloads\\Compressed\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the required details in search certeria\n",
    "search_job = driver.find_element_by_xpath(\"//div[@class = 'inpWrap']/input[@id='qsb-keyword-sugg']\")\n",
    "search_job.send_keys(\"Data Analyst\")\n",
    "search_loc = driver.find_element_by_xpath(\"//div[@class = 'inpWrap']/input[@id='qsb-location-sugg']\")\n",
    "search_loc.send_keys(\"Banglore\")\n",
    "search_btn = driver.find_element_by_xpath(\"//div[@class = 'search-btn']//button[@class = 'btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXEPERIENCE</th>\n",
       "      <th>JOB</th>\n",
       "      <th>COMPANY</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>LOCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-2 Yrs</td>\n",
       "      <td>Market Unit - Data Business Analyst (11)</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Data Analyst Analyzing</td>\n",
       "      <td>Cistup Indian Institute of Science</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Analyst-Finance Data Maintenance</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Analyst-Data Management</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Senior Analyst-Data Visualization</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Senior Analyst-Data Management</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Senior Analyst-Data Management</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Senior Analyst-Data Visualization</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Senior Analyst-Finance Data Maintenance</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  EXEPERIENCE                                       JOB  \\\n",
       "2     1-2 Yrs  Market Unit - Data Business Analyst (11)   \n",
       "0     2-5 Yrs                    Data Analyst Analyzing   \n",
       "4     3-5 Yrs          Analyst-Finance Data Maintenance   \n",
       "6     3-5 Yrs                   Analyst-Data Management   \n",
       "3     3-6 Yrs                              Data Analyst   \n",
       "1     5-8 Yrs         Senior Analyst-Data Visualization   \n",
       "5     5-8 Yrs            Senior Analyst-Data Management   \n",
       "7     5-8 Yrs            Senior Analyst-Data Management   \n",
       "8     5-8 Yrs         Senior Analyst-Data Visualization   \n",
       "9     5-8 Yrs   Senior Analyst-Finance Data Maintenance   \n",
       "\n",
       "                              COMPANY         SALARY             LOCATION  \n",
       "2         Accenture Solutions Pvt Ltd  Not disclosed  Bangalore/Bengaluru  \n",
       "0  Cistup Indian Institute of Science  Not disclosed  Bangalore/Bengaluru  \n",
       "4         Accenture Solutions Pvt Ltd  Not disclosed  Bangalore/Bengaluru  \n",
       "6         Accenture Solutions Pvt Ltd  Not disclosed  Bangalore/Bengaluru  \n",
       "3            Myntra Designs Pvt. Ltd.  Not disclosed  Bangalore/Bengaluru  \n",
       "1         Accenture Solutions Pvt Ltd  Not disclosed  Bangalore/Bengaluru  \n",
       "5         Accenture Solutions Pvt Ltd  Not disclosed  Bangalore/Bengaluru  \n",
       "7         Accenture Solutions Pvt Ltd  Not disclosed  Bangalore/Bengaluru  \n",
       "8         Accenture Solutions Pvt Ltd  Not disclosed  Bangalore/Bengaluru  \n",
       "9         Accenture Solutions Pvt Ltd  Not disclosed  Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title = []# name of the job\n",
    "company_name = []# name of the company\n",
    "exp = []# experience as per post\n",
    "salary = []# salary as per advert\n",
    "loc = []#Location as per advert\n",
    "\n",
    "time.sleep(5) #am setting time as 5 since it takes more time to load the page\n",
    "\n",
    "#sorting the required information and storing in the list.\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'info fleft']//a[@class = 'title fw500 ellipsis']\")[:10]:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'info fleft']//a[@class = 'subTitle ellipsis fleft']\")[:10]:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class = 'mt-7']//li[@class = 'fleft grey-text br2 placeHolderLi location']//span[@class = 'ellipsis fleft fs12 lh16']\")[:10]:\n",
    "    loc.append(i.text)        \n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class = 'mt-7']//li[@class = 'fleft grey-text br2 placeHolderLi experience']//span[@class = 'ellipsis fleft fs12 lh16']\")[:10]:\n",
    "    exp.append(i.text)\n",
    "        \n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class = 'mt-7']//li[@class = 'fleft grey-text br2 placeHolderLi salary']//span[@class = 'ellipsis fleft fs12 lh16']\")[:10]:\n",
    "    salary.append(i.text)\n",
    "    \n",
    "driver.quit()#exiting the driver post scraping the information\n",
    "\n",
    "#storing the data in a DataFrame.\n",
    "Data_Analyst_jobs_Banglore = pd.DataFrame({ \"EXEPERIENCE\": exp, \"JOB\" : job_title ,\"COMPANY\": company_name ,\n",
    "                                           \"SALARY\" : salary,\"LOCATION\" :loc})\n",
    "                                           \n",
    "Data_Analyst_jobs_Banglore.sort_values(by = [\"EXEPERIENCE\"])    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note- 1. All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the required details in search certeria.\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\akans\\Downloads\\Compressed\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "search_job = driver.find_element_by_xpath(\"//div[@class = 'inpWrap']/input[@id='qsb-keyword-sugg']\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "search_loc = driver.find_element_by_xpath(\"//div[@class = 'inpWrap']/input[@id='qsb-location-sugg']\")\n",
    "search_loc.send_keys(\"Banglore\")\n",
    "search_btn = driver.find_element_by_xpath(\"//div[@class = 'search-btn']//button[@class = 'btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []#title of job\n",
    "company_name = []#name of company\n",
    "exp = []#Exeperience Required as per job advert\n",
    "salary = []#Salary offered by company\n",
    "loc = []#Location as per advert\n",
    "item = []# Dummy list to store hyperlink of each advert\n",
    "skill = [] #Skill(s) required for the job opening\n",
    "skills= []#Skill(s) required for the job opening\n",
    "des = []# description of the job\n",
    "date = [] #Date of post\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#sorting the required information and storing in the list.\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'info fleft']//a[@class = 'title fw500 ellipsis']\")[:10]:\n",
    "    job_title.append(i.text)\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'info fleft']//a[@class = 'subTitle ellipsis fleft']\")[:10]:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class = 'mt-7']//li[@class = 'fleft grey-text br2 placeHolderLi experience']//span[@class = 'ellipsis fleft fs12 lh16']\")[:10]:\n",
    "    exp.append(i.text)\n",
    "        \n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class = 'mt-7']//li[@class = 'fleft grey-text br2 placeHolderLi salary']//span[@class = 'ellipsis fleft fs12 lh16']\")[:10]:\n",
    "    salary.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class = 'mt-7']//li[@class = 'fleft grey-text br2 placeHolderLi location']//span[@class = 'ellipsis fleft fs12 lh16']\")[:10]:\n",
    "    loc.append(i.text)    \n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'info fleft']//a[@class = 'title fw500 ellipsis']\")[:10]:\n",
    "    item.append(i.get_attribute('href'))\n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'type br2 fleft grey']//span[@class = 'fleft fw500']\")[:10]:\n",
    "    date.append(i.text)       \n",
    "\n",
    "driver.quit()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting all job description by entering into every job advert.\n",
    "for i in item:\n",
    "    driver = webdriver.Chrome(r\"C:\\Users\\akans\\Downloads\\Compressed\\chromedriver_win32\\chromedriver.exe\")\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    DES = driver.find_elements_by_xpath(\"//section[@class = 'JD av_textblock_section']/div[@class = 'nConfig_textblock ']/div[@class = 'clearboth description']\") \\\n",
    "    or driver.find_elements_by_xpath(\"//section[@class = 'job-desc']/div[@class = 'dang-inner-html']\")\n",
    "    \n",
    "    for i in DES:\n",
    "        des.append(i.text.replace(\"\\n\",\"\")) \n",
    "\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class = 'key-skill']/div\"):\n",
    "        skill.append(i.text)\n",
    "        skill = [' '.join(skill)]       \n",
    " \n",
    "    driver.close()\n",
    "\n",
    "for i in skill:\n",
    "    skills.append(i.split(\"Key Skills\"))\n",
    "skills= skills[0]\n",
    "skills.remove(\"\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXPERIENCE_REQ</th>\n",
       "      <th>JOB_TITLE</th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "      <th>REQ_SKILLS</th>\n",
       "      <th>SALARY_OFFERED</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>JD</th>\n",
       "      <th>POST_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-1 Yrs</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>CronJ IT Technologies Private Limited</td>\n",
       "      <td>TensorflowJavaC++CphythonData StructuresArtif...</td>\n",
       "      <td>3,50,000 - 5,00,000 PA.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Responsibilities and DutiesCreate innovative s...</td>\n",
       "      <td>3 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-1 Yrs</td>\n",
       "      <td>Opportunity For Data Scientist Internship - Be...</td>\n",
       "      <td>Corner Stone Solutions</td>\n",
       "      <td>NLPOpencvArtificial Intelligence Data Science...</td>\n",
       "      <td>1,00,000 - 3,00,000 PA.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Location - Bangalore / BengaluruDuration- 6 Mo...</td>\n",
       "      <td>10 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>HiveRCloud ComputingData ScientistComputer Vi...</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Roles and Responsibilities- Selecting features...</td>\n",
       "      <td>3 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>TensorflowObject DetectionAlgorithm Developme...</td>\n",
       "      <td>7,00,000 - 15,00,000 PA.</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Roles and ResponsibilitiesMust have strong Pyt...</td>\n",
       "      <td>10 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Associate Data Scientist - CRM &amp; Loyalty</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>Direct MarketingMultivariate AnalysisR Data S...</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>The RoleGeneral Position DefinitionThis role w...</td>\n",
       "      <td>29 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Data Scientist/Senior Data Scientist</td>\n",
       "      <td>GANIT BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Predictive ModelingManufacturing AnalyticsPyt...</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>About Ganit IncFounded by senior industry expe...</td>\n",
       "      <td>3 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Data Scientist/ Analyst</td>\n",
       "      <td>Becton Dickinson India Pvt. Ltd</td>\n",
       "      <td>RHiveHadoopData AnalyticsMachine LearningPyth...</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Roles and Responsibilitiesob Description Summa...</td>\n",
       "      <td>12 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Global Medical Data Scientist</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>SQL DatabricksText AnalyticsArtificial Intell...</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>This is an ideal role for an experienced candi...</td>\n",
       "      <td>2 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6-10 Yrs</td>\n",
       "      <td>DBCG IND - GAMMA Senior Data Scientist</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Computer scienceadvanced analyticsSDSdata sci...</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Mumbai, New Delhi, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>What Youll DoWe re looking for a passionat...</td>\n",
       "      <td>5 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Data Scientist || Data Analyst || Data science</td>\n",
       "      <td>Inspiration Manpower Consultancy Pvt. Ltd.</td>\n",
       "      <td>Data ScienceJavaREDAStatistical ModelingData ...</td>\n",
       "      <td>14,00,000 - 22,50,000 PA.</td>\n",
       "      <td>Navi Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Job descriptionJob Summary and Key Responsibil...</td>\n",
       "      <td>9 DAYS AGO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  EXPERIENCE_REQ                                          JOB_TITLE  \\\n",
       "0        0-1 Yrs                                     Data Scientist   \n",
       "1        0-1 Yrs  Opportunity For Data Scientist Internship - Be...   \n",
       "3        2-5 Yrs                  Data Scientist - Machine Learning   \n",
       "7        2-7 Yrs  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "9        3-5 Yrs           Associate Data Scientist - CRM & Loyalty   \n",
       "6        4-8 Yrs               Data Scientist/Senior Data Scientist   \n",
       "2       5-10 Yrs                            Data Scientist/ Analyst   \n",
       "8       5-10 Yrs                      Global Medical Data Scientist   \n",
       "5       6-10 Yrs             DBCG IND - GAMMA Senior Data Scientist   \n",
       "4       6-11 Yrs     Data Scientist || Data Analyst || Data science   \n",
       "\n",
       "                                 COMPANY_NAME  \\\n",
       "0       CronJ IT Technologies Private Limited   \n",
       "1                      Corner Stone Solutions   \n",
       "3                                 AugmatrixGo   \n",
       "7                                    CES Ltd.   \n",
       "9         Shell India Markets Private Limited   \n",
       "6    GANIT BUSINESS SOLUTIONS PRIVATE LIMITED   \n",
       "2             Becton Dickinson India Pvt. Ltd   \n",
       "8     GlaxoSmithKline Pharmaceuticals Limited   \n",
       "5                     Boston Consulting Group   \n",
       "4  Inspiration Manpower Consultancy Pvt. Ltd.   \n",
       "\n",
       "                                          REQ_SKILLS  \\\n",
       "0   TensorflowJavaC++CphythonData StructuresArtif...   \n",
       "1   NLPOpencvArtificial Intelligence Data Science...   \n",
       "3   HiveRCloud ComputingData ScientistComputer Vi...   \n",
       "7   TensorflowObject DetectionAlgorithm Developme...   \n",
       "9   Direct MarketingMultivariate AnalysisR Data S...   \n",
       "6   Predictive ModelingManufacturing AnalyticsPyt...   \n",
       "2   RHiveHadoopData AnalyticsMachine LearningPyth...   \n",
       "8   SQL DatabricksText AnalyticsArtificial Intell...   \n",
       "5   Computer scienceadvanced analyticsSDSdata sci...   \n",
       "4   Data ScienceJavaREDAStatistical ModelingData ...   \n",
       "\n",
       "              SALARY_OFFERED  \\\n",
       "0    3,50,000 - 5,00,000 PA.   \n",
       "1    1,00,000 - 3,00,000 PA.   \n",
       "3              Not disclosed   \n",
       "7   7,00,000 - 15,00,000 PA.   \n",
       "9              Not disclosed   \n",
       "6              Not disclosed   \n",
       "2              Not disclosed   \n",
       "8              Not disclosed   \n",
       "5              Not disclosed   \n",
       "4  14,00,000 - 22,50,000 PA.   \n",
       "\n",
       "                                            LOCATION  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "7  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "9                                Bangalore/Bengaluru   \n",
       "6  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...   \n",
       "2                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "5    Mumbai, New Delhi, Chennai, Bangalore/Bengaluru   \n",
       "4                   Navi Mumbai, Bangalore/Bengaluru   \n",
       "\n",
       "                                                  JD    POST_DATE  \n",
       "0  Responsibilities and DutiesCreate innovative s...   3 DAYS AGO  \n",
       "1  Location - Bangalore / BengaluruDuration- 6 Mo...  10 DAYS AGO  \n",
       "3  Roles and Responsibilities- Selecting features...   3 DAYS AGO  \n",
       "7  Roles and ResponsibilitiesMust have strong Pyt...  10 DAYS AGO  \n",
       "9  The RoleGeneral Position DefinitionThis role w...  29 DAYS AGO  \n",
       "6  About Ganit IncFounded by senior industry expe...   3 DAYS AGO  \n",
       "2  Roles and Responsibilitiesob Description Summa...  12 DAYS AGO  \n",
       "8  This is an ideal role for an experienced candi...   2 DAYS AGO  \n",
       "5      What Youll DoWe re looking for a passionat...   5 DAYS AGO  \n",
       "4  Job descriptionJob Summary and Key Responsibil...   9 DAYS AGO  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Storing our data into Data Frame.\n",
    "DataScientist_jobs_Banglore = pd.DataFrame({\"EXPERIENCE_REQ\" : exp, \n",
    "                                            \"JOB_TITLE\" : job_title,\n",
    "                                            \"COMPANY_NAME\" : company_name,\n",
    "                                            \"REQ_SKILLS\" : skills,\n",
    "                                            \"SALARY_OFFERED\" : salary, \n",
    "                                            \"LOCATION\" : loc,\n",
    "                                            \"JD\" : des,\n",
    "                                            \"POST_DATE\" : date\n",
    "                                           })\n",
    "                                           \n",
    "DataScientist_jobs_Banglore.sort_values(by = [\"EXPERIENCE_REQ\"]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXEPERIENCE_REQ</th>\n",
       "      <th>JOB_TITLE</th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>POST_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Data Scientist Machine Learning</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>30+ DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Msg.ai</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>30+ DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>itForte Staffing Services Private Ltd.</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>30+ DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Data Scientist | Python | Machine Learning | D...</td>\n",
       "      <td>Careerera</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>4,75,000 - 9,75,000 PA.</td>\n",
       "      <td>9 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NatWest Group</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>3 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NatWest Group</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>9 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NatWest Group</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>9 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Data Scientist/Data Analyst - Python/Machine L...</td>\n",
       "      <td>Change leaders</td>\n",
       "      <td>Mumbai, Ghaziabad</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>10 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>GCP Presales AIML Architect &amp; Data Scientist (...</td>\n",
       "      <td>Lecan Solutions Pvt Ltd</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>10 DAYS AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>GCP Presales AIML Architect &amp; Data Scientist (...</td>\n",
       "      <td>Lecan Solutions Pvt Ltd</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>10 DAYS AGO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  EXEPERIENCE_REQ                                          JOB_TITLE  \\\n",
       "9         1-3 Yrs                    Data Scientist Machine Learning   \n",
       "2         3-5 Yrs                                     Data Scientist   \n",
       "1         3-8 Yrs                                     Data Scientist   \n",
       "5         3-8 Yrs  Data Scientist | Python | Machine Learning | D...   \n",
       "0         4-8 Yrs                                     Data Scientist   \n",
       "3         4-8 Yrs                                     Data Scientist   \n",
       "4         4-8 Yrs                                     Data Scientist   \n",
       "6        5-10 Yrs  Data Scientist/Data Analyst - Python/Machine L...   \n",
       "7        6-11 Yrs  GCP Presales AIML Architect & Data Scientist (...   \n",
       "8        6-11 Yrs  GCP Presales AIML Architect & Data Scientist (...   \n",
       "\n",
       "                             COMPANY_NAME                LOCATION  \\\n",
       "9                               Delhivery        Gurgaon/Gurugram   \n",
       "2                                  Msg.ai        Gurgaon/Gurugram   \n",
       "1  itForte Staffing Services Private Ltd.        Gurgaon/Gurugram   \n",
       "5                               Careerera  Noida(Sector-59 Noida)   \n",
       "0                           NatWest Group             Delhi / NCR   \n",
       "3                           NatWest Group        Gurgaon/Gurugram   \n",
       "4                           NatWest Group             Delhi / NCR   \n",
       "6                          Change leaders       Mumbai, Ghaziabad   \n",
       "7                 Lecan Solutions Pvt Ltd                   Noida   \n",
       "8                 Lecan Solutions Pvt Ltd                   Noida   \n",
       "\n",
       "                    SALARY     POST_DATE  \n",
       "9            Not disclosed  30+ DAYS AGO  \n",
       "2            Not disclosed  30+ DAYS AGO  \n",
       "1            Not disclosed  30+ DAYS AGO  \n",
       "5  4,75,000 - 9,75,000 PA.    9 DAYS AGO  \n",
       "0            Not disclosed    3 DAYS AGO  \n",
       "3            Not disclosed    9 DAYS AGO  \n",
       "4            Not disclosed    9 DAYS AGO  \n",
       "6            Not disclosed   10 DAYS AGO  \n",
       "7            Not disclosed   10 DAYS AGO  \n",
       "8            Not disclosed   10 DAYS AGO  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entering the required details in search certeria.\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\akans\\Downloads\\Compressed\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "search_job = driver.find_element_by_xpath(\"//div[@class = 'inpWrap']/input[@id='qsb-keyword-sugg']\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "search_btn = driver.find_element_by_xpath(\"//div[@class = 'search-btn']//button[@class = 'btn']\")\n",
    "search_btn.click()\n",
    "\n",
    "time.sleep(3)\n",
    "#Clicking the filter required.\n",
    "Filter1 = driver.find_element_by_xpath(\"//label[@for='chk-Delhi / NCR-cityTypeGid-']/i\")\n",
    "Filter1.click()\n",
    "time.sleep(3)\n",
    "#Clicking the filter required.\n",
    "Filter2 = driver.find_element_by_xpath(\"//label[@for='chk-3-6 Lakhs-ctcFilter-']/i\")\n",
    "Filter2.click()\n",
    "\n",
    "job_title = []#title of job\n",
    "company_name = []#title of Company\n",
    "exp = []#Experience req\n",
    "salary = []# Salary offered\n",
    "date = []# Date of post\n",
    "loc = []#Location of the job\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#sorting the required information and storing in the list.\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'info fleft']//a[@class = 'title fw500 ellipsis']\")[:10]:\n",
    "    job_title.append(i.text)\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'info fleft']//a[@class = 'subTitle ellipsis fleft']\")[:10]:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class = 'mt-7']//li[@class = 'fleft grey-text br2 placeHolderLi experience']//span[@class = 'ellipsis fleft fs12 lh16']\")[:10]:\n",
    "    exp.append(i.text)\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class = 'mt-7']//li[@class = 'fleft grey-text br2 placeHolderLi location']//span[@class = 'ellipsis fleft fs12 lh16']\")[:10]:\n",
    "    loc.append(i.text)        \n",
    "        \n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class = 'mt-7']//li[@class = 'fleft grey-text br2 placeHolderLi salary']//span[@class = 'ellipsis fleft fs12 lh16']\")[:10]:\n",
    "    salary.append(i.text)\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'type br2 fleft grey']//span[@class = 'fleft fw500']\")[:10]:\n",
    "    date.append(i.text)       \n",
    "    \n",
    "    \n",
    "driver.quit()\n",
    "\n",
    "#storing all the required information into DataFrame.\n",
    "\n",
    "DataScientist_JOBDelhi= pd.DataFrame({ \"EXEPERIENCE_REQ\": exp, \"JOB_TITLE\" : job_title ,\"COMPANY_NAME\": company_name , \n",
    "                                           \"LOCATION\" : loc,\n",
    "                                           \"SALARY\" : salary,\n",
    "                                          \"POST_DATE\" : date})\n",
    "                                           \n",
    "DataScientist_JOBDelhi.sort_values(by = [\"EXEPERIENCE_REQ\"])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it\n",
    "5. Now scrape data from this page as usual\n",
    "6. repeat this until you get data for 100 sunglasses.\n",
    "\n",
    "Note that all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the required details in search certeria.\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\akans\\Downloads\\Compressed\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "driver.maximize_window()\n",
    "\n",
    "#closing the login Pop-up\n",
    "time.sleep(3)\n",
    "pop_up = driver.find_element_by_xpath(\"//div[@class='_2QfC02']/button[@class = '_2KpZ6l _2doB4z']\")\n",
    "pop_up.click()\n",
    "\n",
    "prod_ser = driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']//input[@type = 'text']\")\n",
    "prod_ser.send_keys(\"sunglasses\")\n",
    "\n",
    "sub_button = driver.find_element_by_xpath(\"//div[@class = 'col-12-12 _2oO9oE']//button[@class = 'L0Z3Pu']\")\n",
    "sub_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting the required information and storing in the list.\n",
    "Brand = []\n",
    "Product_Description= []\n",
    "Price = []\n",
    "Discount =[]\n",
    "\n",
    "while True:\n",
    "    \n",
    "    time.sleep(3)\n",
    "        \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= '_2B099V']//div[@class = '_2WkVRV']\"):\n",
    "        Brand.append(i.text)\n",
    "        if len(Brand) == 100:\n",
    "            break\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= '_2B099V']//a\"):\n",
    "        Product_Description.append(i.get_attribute('title'))\n",
    "        if len(Product_Description) == 200:\n",
    "            break\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= '_25b18c']//div[@class = '_30jeq3']\"):\n",
    "        Price.append(i.text) \n",
    "        if len(Price) == 100:\n",
    "            break    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= '_3Ay6Sb']/span\"):\n",
    "        Discount.append(i.text)\n",
    "        if len(Discount) == 100:\n",
    "            break  \n",
    "            \n",
    "    if len(Discount) == 100:\n",
    "        break\n",
    "        \n",
    "    for j in driver.find_elements_by_xpath(\"//nav[@class ='yFHi8N']/a[@class = '_1LKTO3']\"):\n",
    "        next=[j.get_attribute(\"href\")]\n",
    "    \n",
    "    time.sleep(3)\n",
    "        \n",
    "    for n in next:\n",
    "        driver.get(n) \n",
    "    \n",
    "driver.close() \n",
    "\n",
    "Product = [] # Since Product_Description have many unwanted information am following this method to clense it.\n",
    "for i in range(0,len(Product_Description)):\n",
    "    if i == 0 or  i/2 == i//2:\n",
    "        Product.append(Product_Description[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aislin</td>\n",
       "      <td>UV Protection, Gradient Butterfly, Wayfarer Su...</td>\n",
       "      <td>₹574</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAMIW COLLECTION</td>\n",
       "      <td>UV Protection Round Sunglasses (53)</td>\n",
       "      <td>₹189</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹758</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹666</td>\n",
       "      <td>16% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection, Mirrored Sports Sunglasses (73)</td>\n",
       "      <td>₹367</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Badfella</td>\n",
       "      <td>Polarized, UV Protection Retro Square Sunglass...</td>\n",
       "      <td>₹269</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (56)</td>\n",
       "      <td>₹759</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹197</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                                Product_Description Price  \\\n",
       "0             Aislin  UV Protection, Gradient Butterfly, Wayfarer Su...  ₹574   \n",
       "1   HAMIW COLLECTION                UV Protection Round Sunglasses (53)  ₹189   \n",
       "2           Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹758   \n",
       "3           Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹666   \n",
       "4           Fastrack  Mirrored, UV Protection Wayfarer Sunglasses (F...  ₹499   \n",
       "..               ...                                                ...   ...   \n",
       "95             NuVew     UV Protection, Mirrored Sports Sunglasses (73)  ₹367   \n",
       "96          Badfella  Polarized, UV Protection Retro Square Sunglass...  ₹269   \n",
       "97          Fastrack  UV Protection, Polarized Wayfarer Sunglasses (56)  ₹759   \n",
       "98            PIRASO              UV Protection Aviator Sunglasses (54)  ₹197   \n",
       "99    ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...  ₹499   \n",
       "\n",
       "   Discount  \n",
       "0   62% off  \n",
       "1   88% off  \n",
       "2   15% off  \n",
       "3   16% off  \n",
       "4   50% off  \n",
       "..      ...  \n",
       "95  70% off  \n",
       "96  73% off  \n",
       "97  15% off  \n",
       "98  87% off  \n",
       "99  77% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating DataFrame.\n",
    "Flipkart_Sunglass = pd.DataFrame({\"Brand\": Brand, \n",
    "                                  \"Product_Description\": Product, \n",
    "                                  \"Price\": Price , \n",
    "                                  \"Discount\": Discount})\n",
    "Flipkart_Sunglass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "As shown in the below image, you have to scrape the tick marked attributes.\n",
    "\n",
    "Also note that all the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the required details in search certeria.\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\akans\\Downloads\\Compressed\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "driver.maximize_window()\n",
    "\n",
    "#closing the login Pop-up\n",
    "time.sleep(3)\n",
    "pop_up = driver.find_element_by_xpath(\"//div[@class='_2QfC02']/button[@class = '_2KpZ6l _2doB4z']\")\n",
    "pop_up.click()\n",
    "\n",
    "prod_ser = driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']//input[@type = 'text']\")\n",
    "prod_ser.send_keys(\"sneakers\")\n",
    "\n",
    "sub_button = driver.find_element_by_xpath(\"//div[@class = 'col-12-12 _2oO9oE']//button[@class = 'L0Z3Pu']\")\n",
    "sub_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>French Connection</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹799</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oxpeo</td>\n",
       "      <td>Colourblocked Trending Multicolor Ultralight c...</td>\n",
       "      <td>₹419</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Perfect &amp; Affordable Combo Pack of 02 Pairs Sn...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SWIGGY</td>\n",
       "      <td>Casual Loafers, Sneakers Shoes for Men Pack of...</td>\n",
       "      <td>₹799</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROCKFIELD</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>SM-162 Sneakers For Men</td>\n",
       "      <td>₹730</td>\n",
       "      <td>23% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROCKFIELD</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bonexy</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand                                Product_Description  \\\n",
       "0   French Connection                                   Sneakers For Men   \n",
       "1               oxpeo  Colourblocked Trending Multicolor Ultralight c...   \n",
       "2              Chevit  Perfect & Affordable Combo Pack of 02 Pairs Sn...   \n",
       "3        Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "4              Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...   \n",
       "..                ...                                                ...   \n",
       "95             SWIGGY  Casual Loafers, Sneakers Shoes for Men Pack of...   \n",
       "96          ROCKFIELD                                   Sneakers For Men   \n",
       "97              SPARX                            SM-162 Sneakers For Men   \n",
       "98          ROCKFIELD                                   Sneakers For Men   \n",
       "99             Bonexy                                   Sneakers For Men   \n",
       "\n",
       "   Price Discount  \n",
       "0   ₹799  60% off  \n",
       "1   ₹419  58% off  \n",
       "2   ₹499  72% off  \n",
       "3   ₹399  60% off  \n",
       "4   ₹474  76% off  \n",
       "..   ...      ...  \n",
       "95  ₹799  67% off  \n",
       "96  ₹499  50% off  \n",
       "97  ₹730  23% off  \n",
       "98  ₹399  60% off  \n",
       "99  ₹499  50% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting the required information and storing in the list.\n",
    "Brand = []\n",
    "Product_Description= []\n",
    "Price = []\n",
    "Discount =[]\n",
    "\n",
    "while True:\n",
    "    \n",
    "    time.sleep(3)\n",
    "        \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= '_2B099V']//div[@class = '_2WkVRV']\"):\n",
    "        Brand.append(i.text)\n",
    "        if len(Brand) == 100:\n",
    "            break\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= '_2B099V']//a\"):\n",
    "        Product_Description.append(i.get_attribute('title'))\n",
    "        if len(Product_Description) == 200:\n",
    "            break\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= '_25b18c']//div[@class = '_30jeq3']\"):\n",
    "        Price.append(i.text) \n",
    "        if len(Price) == 100:\n",
    "            break    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= '_3Ay6Sb']/span\"):\n",
    "        Discount.append(i.text)\n",
    "        if len(Discount) == 100:\n",
    "            break  \n",
    "            \n",
    "    if len(Discount) == 100:\n",
    "        break\n",
    "        \n",
    "    for j in driver.find_elements_by_xpath(\"//nav[@class ='yFHi8N']/a[@class = '_1LKTO3']\"):\n",
    "        next=[j.get_attribute(\"href\")]\n",
    "    \n",
    "    time.sleep(3)\n",
    "        \n",
    "    for n in next:\n",
    "        driver.get(n) \n",
    "    \n",
    "driver.close() \n",
    "\n",
    "Product = [] # Since Product_Description have many unwanted information am following this method to clense it.\n",
    "for i in range(0,len(Product_Description)):\n",
    "    if i == 0 or  i/2 == i//2:\n",
    "        Product.append(Product_Description[i])\n",
    "\n",
    "#Creating DataFrame.\n",
    "Flipkart_sneakers = pd.DataFrame({\"Brand\": Brand, \n",
    "                                  \"Product_Description\": Product, \n",
    "                                  \"Price\": Price , \n",
    "                                  \"Discount\": Discount})\n",
    "Flipkart_sneakers        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set second Price filter and  Color filter to “Black”, as shown in the below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image.\n",
    "Note that applying the filter and scraping the data, everything should be done through code only and there should not be any manual step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the required details in search certeria.\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\akans\\Downloads\\Compressed\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.myntra.com/shoes\")\n",
    "driver.maximize_window()\n",
    "\n",
    "time.sleep(3)\n",
    "#selecting black color.\n",
    "Filter2 = driver.find_elements_by_xpath(\"//li[@class ='colour-listItem']//label[@class ='common-customCheckbox']/div[@class = 'common-checkboxIndicator']\") \n",
    "Filter2[0].click()\n",
    "\n",
    "time.sleep(5)\n",
    "#setting price filter\n",
    "Filter1 = driver.find_elements_by_xpath(\"//ul[@class ='price-list']//label[@class ='common-customCheckbox vertical-filters-label']/div[@class = 'common-checkboxIndicator']\") \n",
    "Filter1[1].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM Running Shoes</td>\n",
       "      <td>11470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR MAX VOLLEY Tennis</td>\n",
       "      <td>6965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Fuse Training Sports Shoes</td>\n",
       "      <td>7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR MAX INFINITY 2 Sneaker</td>\n",
       "      <td>7050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Infinity Running</td>\n",
       "      <td>12396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Solid Leather Wedges</td>\n",
       "      <td>9490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Solid Wedges</td>\n",
       "      <td>8490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Leather Solid Pumps</td>\n",
       "      <td>11990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Slip-On Sneakers</td>\n",
       "      <td>8499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Leather Block Heels</td>\n",
       "      <td>9990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Brand                     description  price\n",
       "0   Nike      Men AIR ZOOM Running Shoes  11470\n",
       "1   Nike       Men AIR MAX VOLLEY Tennis   6965\n",
       "2   Puma  Men Fuse Training Sports Shoes   7999\n",
       "3   Nike  Men AIR MAX INFINITY 2 Sneaker   7050\n",
       "4   Nike      Men React Infinity Running  12396\n",
       "..   ...                             ...    ...\n",
       "95  Geox            Solid Leather Wedges   9490\n",
       "96  Geox              Women Solid Wedges   8490\n",
       "97  Geox       Women Leather Solid Pumps  11990\n",
       "98  Geox          Women Slip-On Sneakers   8499\n",
       "99  Geox       Women Leather Block Heels   9990\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brand,description,price = [], [], []\n",
    "q = 0\n",
    "\n",
    "while q<2:\n",
    "    time.sleep(3)\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= 'product-productMetaInfo']//h3[@class = 'product-brand']\"):\n",
    "        Brand.append(i.text)\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= 'product-productMetaInfo']//h4[@class = 'product-product']\"):\n",
    "        description.append(i.text)\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class= 'product-productMetaInfo']//div[@class = 'product-price']\"):\n",
    "        price.append(i.text)\n",
    "    \n",
    "    nxt = driver.find_element_by_xpath(\"//a[@rel = 'next']\")\n",
    "    nxt.click()\n",
    "    q +=1\n",
    "\n",
    "driver.close()     \n",
    "price= [i.split('Rs. ')[1] for i in price]   \n",
    "\n",
    "myntra_blackshoes = pd.DataFrame({\"Brand\":Brand,\"description\":description,\"price\":price})\n",
    "myntra_blackshoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:\n",
    "\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the required details in search certeria.\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\akans\\Downloads\\Compressed\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "driver.maximize_window()\n",
    "\n",
    "search_Box = driver.find_element_by_xpath(\"//div[@class = 'nav-search-field ']/input[@type='text']\")\n",
    "search_Box.send_keys(\"Laptop\")\n",
    "search_btn = driver.find_element_by_xpath(\"//input[@id= 'nav-search-submit-button']\")\n",
    "search_btn.click()\n",
    "\n",
    "fltr_btn = driver.find_elements_by_xpath(\"//ul[@aria-labelledby= 'p_n_feature_thirteen_browse-bin-title']//div[@class= 'a-checkbox a-checkbox-fancy s-navigation-checkbox aok-float-left']\")\n",
    "fltr_btn[-3].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_record(item):\n",
    "    \"\"\"Extract and return the Data from a Single record\"\"\"\n",
    "    \n",
    "    #Description\n",
    "    atag = item.h2.a\n",
    "    description = atag.text.strip()\n",
    "    \n",
    "    try:\n",
    "        #Price\n",
    "        price_parent = item.find('span', 'a-price')\n",
    "        price = price_parent.find('span', 'a-offscreen').text\n",
    "    except AttributeError: #Attribute error handeling\n",
    "        price = ''\n",
    "    \n",
    "    try:\n",
    "        #Rating\n",
    "        rating = item.i.text\n",
    "    except AttributeError: #Attribute error handeling\n",
    "        rating = ''\n",
    "        \n",
    "        \n",
    "    result = (description, price, rating)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LifeDigital ZED AIR CX7 15.6 IPS FHD Screen Bl...</td>\n",
       "      <td></td>\n",
       "      <td>₹35,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>₹83,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP 14 Thin &amp; Light 14-inch FHD Laptop (11th Ge...</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "      <td>₹76,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Renewed) Lenovo Thinkpad Yoga S1 Laptop (CORE...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "      <td>₹38,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>53962.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dell Alienware m15(R3) 15.6-inch FHD Gaming La...</td>\n",
       "      <td>2.7 out of 5 stars</td>\n",
       "      <td>₹1,98,590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>₹1,35,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LifeDigital ZED AIR CX7 15.6 IPS FHD Screen Bl...</td>\n",
       "      <td>3.5 out of 5 stars</td>\n",
       "      <td>₹39,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion Gaming 11th Gen Intel Core i7 Proc...</td>\n",
       "      <td></td>\n",
       "      <td>₹83,128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title             Ratings  \\\n",
       "0  LifeDigital ZED AIR CX7 15.6 IPS FHD Screen Bl...                       \n",
       "1  Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...  5.0 out of 5 stars   \n",
       "2  HP 14 Thin & Light 14-inch FHD Laptop (11th Ge...  4.6 out of 5 stars   \n",
       "3  (Renewed) Lenovo Thinkpad Yoga S1 Laptop (CORE...  1.0 out of 5 stars   \n",
       "4  Mi Notebook Horizon Edition 14 Intel Core i5-1...  4.3 out of 5 stars   \n",
       "5  Dell Alienware m15(R3) 15.6-inch FHD Gaming La...  2.7 out of 5 stars   \n",
       "6  Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...  4.3 out of 5 stars   \n",
       "7  LifeDigital ZED AIR CX7 15.6 IPS FHD Screen Bl...  3.5 out of 5 stars   \n",
       "8  HP Pavilion Gaming 11th Gen Intel Core i7 Proc...                       \n",
       "9  Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...  4.3 out of 5 stars   \n",
       "\n",
       "       Price  \n",
       "0    ₹35,990  \n",
       "1    ₹83,990  \n",
       "2    ₹76,500  \n",
       "3    ₹38,990  \n",
       "4   53962.00  \n",
       "5  ₹1,98,590  \n",
       "6  ₹1,35,490  \n",
       "7    ₹39,990  \n",
       "8    ₹83,128  \n",
       "9             "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = []\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "results = soup.find_all('div',{'data-component-type' : 's-search-result'})\n",
    "\n",
    "for item in results:\n",
    "    record = extract_record(item)\n",
    "    if record:\n",
    "        records.append(record)\n",
    "        \n",
    "records = records[:10]\n",
    "\n",
    "driver.close()\n",
    "\n",
    "title =[]\n",
    "Ratings =[]\n",
    "Price =[]\n",
    "\n",
    "for i in records:\n",
    "    title.append(i[0])\n",
    "    Ratings.append(i[2])\n",
    "    Price.append(i[1])\n",
    "    \n",
    "intel_core_i7_amazon = pd.DataFrame({\"Title\":title,\"Ratings\":Ratings,\"Price\":Price})\n",
    "intel_core_i7_amazon            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS ROG G703GI-E5148T 17.3-inch FHD 144Hz/3ms...</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>₹5,22,077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dell XPS 9570 15.6-inch UHD Laptop (8th Gen i9...</td>\n",
       "      <td>2.3 out of 5 stars</td>\n",
       "      <td>₹2,27,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...</td>\n",
       "      <td>3.3 out of 5 stars</td>\n",
       "      <td>₹2,59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Omen X 2S Core i9 9th Gen 15.6-inch Dual Sc...</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>₹3,64,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell Alienware 17 Area 51 9thGeneration Corei9...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Renewed) Dell G7 15 Gaming 7588 Laptop Intel ...</td>\n",
       "      <td></td>\n",
       "      <td>₹1,14,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS ROG Strix Scar 15 (2020), 15.6\" FHD 300Hz...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "      <td>₹2,14,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dell Alienware m15(R3) 15.6-inch UHD Gaming La...</td>\n",
       "      <td>2.7 out of 5 stars</td>\n",
       "      <td>₹3,42,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS ZenBook Pro Duo UX581 Intel Core i9 9th G...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>₹2,69,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dell G7 7500 15.6inch FHD 300 Hz Display Gamin...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>₹2,06,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title             Ratings  \\\n",
       "0  ASUS ROG G703GI-E5148T 17.3-inch FHD 144Hz/3ms...  3.9 out of 5 stars   \n",
       "1  Dell XPS 9570 15.6-inch UHD Laptop (8th Gen i9...  2.3 out of 5 stars   \n",
       "2  ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...  3.3 out of 5 stars   \n",
       "3  HP Omen X 2S Core i9 9th Gen 15.6-inch Dual Sc...  4.4 out of 5 stars   \n",
       "4  Dell Alienware 17 Area 51 9thGeneration Corei9...  4.2 out of 5 stars   \n",
       "5  (Renewed) Dell G7 15 Gaming 7588 Laptop Intel ...                       \n",
       "6  ASUS ROG Strix Scar 15 (2020), 15.6\" FHD 300Hz...  1.0 out of 5 stars   \n",
       "7  Dell Alienware m15(R3) 15.6-inch UHD Gaming La...  2.7 out of 5 stars   \n",
       "8  ASUS ZenBook Pro Duo UX581 Intel Core i9 9th G...  4.0 out of 5 stars   \n",
       "9  Dell G7 7500 15.6inch FHD 300 Hz Display Gamin...  5.0 out of 5 stars   \n",
       "\n",
       "       Price  \n",
       "0  ₹5,22,077  \n",
       "1  ₹2,27,200  \n",
       "2  ₹2,59,990  \n",
       "3  ₹3,64,800  \n",
       "4             \n",
       "5  ₹1,14,490  \n",
       "6  ₹2,14,990  \n",
       "7  ₹3,42,990  \n",
       "8  ₹2,69,990  \n",
       "9  ₹2,06,990  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entering the required details in search certeria.\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\akans\\Downloads\\Compressed\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "driver.maximize_window()\n",
    "\n",
    "search_Box = driver.find_element_by_xpath(\"//div[@class = 'nav-search-field ']/input[@type='text']\")\n",
    "search_Box.send_keys(\"Laptop\")\n",
    "search_btn = driver.find_element_by_xpath(\"//input[@id= 'nav-search-submit-button']\")\n",
    "search_btn.click()\n",
    "\n",
    "fltr_btn = driver.find_elements_by_xpath(\"//ul[@aria-labelledby= 'p_n_feature_thirteen_browse-bin-title']//div[@class= 'a-checkbox a-checkbox-fancy s-navigation-checkbox aok-float-left']\")\n",
    "fltr_btn[-2].click()\n",
    "\n",
    "def extract_record(item):\n",
    "    \"\"\"Extract and return the Data from a Single record\"\"\"\n",
    "    \n",
    "    #Description\n",
    "    atag = item.h2.a\n",
    "    description = atag.text.strip()\n",
    "    \n",
    "    try:\n",
    "        #Price\n",
    "        price_parent = item.find('span', 'a-price')\n",
    "        price = price_parent.find('span', 'a-offscreen').text\n",
    "    except AttributeError: #Attribute error handeling\n",
    "        price = ''\n",
    "    \n",
    "    try:\n",
    "        #Rating\n",
    "        rating = item.i.text\n",
    "    except AttributeError: #Attribute error handeling\n",
    "        rating = ''\n",
    "        \n",
    "        \n",
    "    result = (description, price, rating)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "records = []\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "results = soup.find_all('div',{'data-component-type' : 's-search-result'})\n",
    "\n",
    "for item in results:\n",
    "    record = extract_record(item)\n",
    "    if record:\n",
    "        records.append(record)\n",
    "        \n",
    "records = records[:10]\n",
    "\n",
    "driver.close()\n",
    "\n",
    "title =[]\n",
    "Ratings =[]\n",
    "Price =[]\n",
    "\n",
    "for i in records:\n",
    "    title.append(i[0])\n",
    "    Ratings.append(i[2])\n",
    "    Price.append(i[1])\n",
    "    \n",
    "intel_core_i9_amazon = pd.DataFrame({\"Title\":title,\"Ratings\":Ratings,\"Price\":Price})\n",
    "intel_core_i9_amazon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
